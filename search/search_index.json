{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CCP-volumeEM guide","text":"<p>Community good practice guide</p> <p></p>"},{"location":"ngff/","title":"Next Generation File Format (NGFF)","text":"<p>The commonly used term Next Generation File Format (NGFF) refers to the OME-Zarr file format developed by the Open Microscopy Environment (OME) for storing and sharing large bioimaging datasets.</p> <p>See this Comparison of OME-Zarr libs including examples of each of the Python packages.</p> <p>The textbook An Introduction to OME-Zarr for Big Bioimaging Data gives a great overview of the NGFF/OME-Zarr format and how to use it in Python. This is using the ome-zarr-models and pydantic-ome-ngff, as well as the core zarr-python package.</p> <p>We recommend the use of persistent metadata together with the image data in dask format.</p>"},{"location":"ngff/#persistent-metadata","title":"Persistent metadata","text":"<pre><code>---\nconfig:\n  themeVariables:\n    fontSize: 20px\n---\nflowchart LR\n    subgraph data_layers[\"Persistent&amp;nbsp;metadata\"]\n        direction TB\n        layers(\"Multiscale Spatial-image&lt;hr&gt;&lt;b&gt;Spatial-image\n&lt;hr&gt;Xarray&lt;hr&gt;Dask array&lt;hr&gt;File store\"):::green\n        image(\"Image data&lt;br&gt;(voxels)\"):::blue --&gt; layers\n        size(\"Pixel size&lt;br&gt;(w,h,d)\"):::yellow --&gt; layers\n        coords(\"Coordinates&lt;br&gt;(x,y,z)\"):::yellow --&gt; layers\n        transforms(\"Transforms&lt;br&gt;[]\"):::yellow --&gt; layers\n    end\n\n    %% Styles\n    %% classDef default font-size:20\n    classDef blue fill:#e0f7fa,stroke:#006064,color:#006064\n    classDef yellow fill:#fff5e9,stroke:#5e4e20,color:#5e4e20\n    classDef green fill:#e8f5e9,stroke:#1b5e20,color:#1b5e20\n\n    linkStyle 0 stroke:#006064\n    linkStyle 1 stroke:#ddbb00\n    linkStyle 2 stroke:#ddbb00\n    linkStyle 3 stroke:#ddbb00</code></pre> <p>The muvis-align project reads OME-Zarr using the ome-zarr-py package, and writes OME-Zarr through multiview-stitcher, which in turn also uses the ome-zarr-py package. It uses persistent metadata together with dask arrays for image data as described before. This metadata is persisted through the OME-Zarr format.</p>"},{"location":"ngff/#basic-example-reading-ome-zarr","title":"Basic example reading OME-Zarr","text":"<pre><code>from ome_zarr.io import parse_url\nfrom ome_zarr.reader import Reader\n\n# Example URL of remote data\nurl = \"https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.5/idr0062A/6001240_labels.zarr\"\n\n# read the image data\nreader = Reader(parse_url(url))\n# nodes may include images, labels etc\nnodes = list(reader())\n# first node will be the image pixel data\nimage_node = nodes[0]\n\n# list of dask arrays at different pyramid levels\ndata = image_node.data\n# dictionary of OME-Zarr metadata\nmetadata = image_node.metadata\n\nfull_size_image_data = data[0]  # access the image data array at full size\naxes = \"\".join([axis[\"name\"] for axis in metadata[\"axes\"]])\n</code></pre>"},{"location":"ngff/#basic-example-writing-ome-zarr","title":"Basic example writing OME-Zarr","text":"<pre><code>import zarr\nfrom ome_zarr.writer import write_image\n\npath = \"path/to/output_image.zarr\"\n\nroot = zarr.open_group(store=path)\n# supports dask data, by default written out at various pyramid sizes\nwrite_image(image=full_size_image_data, group=root, axes=axes)\n</code></pre>"},{"location":"overview/","title":"Overview","text":"<p>Overview</p> <p></p> <p>Work in progress</p>"}]}